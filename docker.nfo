__DOCKERS_START__
__DOCKER_START__ name=caddy req=true
__CMD_START__
mkdir -p /docker/caddy/{conf,log}
__CMD_END__
__EOFS_START__
__EOF_START__ /docker/caddy/docker-compose.yml
services:
  caddy:
    container_name: caddy
    image: ghcr.io/caddybuilds/caddy-cloudflare:latest
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp"
    cap_add:
      - NET_ADMIN
    volumes:
      - ./conf:/etc/caddy
      - ./log:/var/log
      - data:/data
      - config:/config
    environment:
      - CLOUDFLARE_API_TOKEN=##API_TOKEN##
volumes:
  data:
  config:
networks:
  default:
    external: true
    name: ##DOCKER_BRIDGE_NM##
__EOF_END__
__EOFS_END__
__DOCKER_END__

__DOCKER_START__ name=portainer req=true 
__CMD_START__
mkdir -p /docker/portainer
__CMD_END__
__EOFS_START__
__EOF_START__ /docker/portainer/docker-compose.yml
services:
  portainer:
    image: portainer/portainer-ce:latest
    container_name: portainer
    restart: unless-stopped
    ports:
      - "9000:9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - data:/data
    deploy:
      resources:
        limits:
          memory: 256M
    environment:
      - TZ=Asia/Seoul
      - PUID=0
      - PGID=0
volumes:
  data:
networks:
  default:
    external: true
    name: ##DOCKER_BRIDGE_NM##
__EOF_END__
__EOF_START__ /docker/docker-all-start.sh
#!/usr/bin/env bash

cd /docker || exit 1

# 다중 서비스 운영하는 폴더
SPECIAL_DIR="ff_plex"
# 예외적으로 건너뛸 폴더들   ("core" "backup" "testdir")
EXCLUDE_DIRS=("core")


# 함수: 예외폴더 여부 체크
is_excluded() {
  local dir=$1
  for e in "${EXCLUDE_DIRS[@]}"; do
    if [ "$dir" = "$e" ]; then
      return 0
    fi
  done
  return 1
}

for dir in */; do
  svc=$(basename "$dir")

  # 예외폴더 건너뜀
  if is_excluded "$svc"; then
    echo "-- $svc: 예외폴더, 건너뜀 --"
    continue
  fi

  if [ -f "$dir/docker-compose.yml" ]; then
    echo "-- $svc 서비스 처리 중: $dir --"
    cd "$dir" || continue

    if docker compose ps -q | grep -q .; then
      echo "   -> 컨테이너 존재: restart 수행"
      docker compose restart
    else
      echo "   -> 컨테이너 없음: up -d 수행"
      docker compose up -d
    fi

    cd ..
  else
    echo "-- $svc: docker-compose.yml 없음, 생략 --"
  fi
done

echo "모든 도커 서비스 처리 완료."
__EOF_END__
__EOF_START__ /docker/docker-all-stop.sh
#!/bin/bash

# 모든 도커 컨테이너 중지 스크립트

echo "모든 도커 컨테이너 중지 시작..."

# 실행 중인 모든 컨테이너 ID 리스트 가져오기
containers=$(docker ps -q)

if [ -z "$containers" ]; then
  echo "중지할 실행 중인 컨테이너가 없습니다."
  exit 0
fi

# 각 컨테이너 중지 반복
for container in $containers; do
    echo "중지 중: 컨테이너 ID $container"
    docker stop "$container"
done

echo "모든 도커 컨테이너가 중지되었습니다."
__EOFS_END__
__EOFS_END__
__CADDYS_START__
__CADDY_START__
    # Portainer
    @portainer host portainer.##DOMAIN##
    handle @portainer {
        reverse_proxy portainer:9000 {
            header_up X-Forwarded-For {remote_host}
            header_up X-Real-IP {remote_host}
        }
    }
__CADDY_END__
__CADDYS_END__
__DOCKER_END__

__DOCKER_START__ name=rclone req=true
__CMD_START__
mkdir -p /docker/rclone && mkdir -p /mnt/rclone/{Cache,Data} && mkdir -p /mnt/backup/docker
__CMD_END__
__EOFS_START__
__EOF_START__ /docker/rclone/docker-compose.yml
services:
  rclone:
    container_name: rclone
    image: ghcr.io/wiserain/rclone:mod
    restart: unless-stopped
    ports:
      - 5574:5574
    devices:
      - /dev/fuse
    cap_add:
      - SYS_ADMIN
    security_opt:
      - apparmor:unconfined
    volumes:
      - ./:/config
      - ./:/log
      - /rclone/Cache:/cache
      - /rclone/Data:/data:rshared
    environment:
      - PUID=0
      - PGID=0
      - TZ=Asia/Seoul
      - RCLONE_LOG_FILE=./rclone_mount.log
      - RCLONE_LOG_LEVEL=ERROR
      - "RCLONE_REMOTE_PATH=google:"
      - RCLONE_REFRESH_ON_MOUNT
      - RCLONE_MOUNT_USER_OPTS=
        --allow-non-empty
        --drive-skip-gdocs
        --user-agent=oci-seoul
        --poll-interval=0
        --buffer-size=16M
        --vfs-read-chunk-size=16M
        --vfs-read-chunk-size-limit 2048M
        --vfs-read-ahead 32M
        --vfs-cache-mode=full
        --vfs-cache-max-size=256G
        --vfs-cache-max-age=480h
        --vfs-cache-poll-interval=5m
        --dir-cache-time=480h
        --read-only
        --no-checksum
        --no-modtime
        --drive-gds-mode=all
        --filter-from=/config/filter.txt
networks:
  default:
    external: true
    name: ##DOCKER_BRIDGE_NM##
__EOF_END__
__EOF_START__ /docker/rclone/rclone.conf
[google]
type = drive
scope = drive
gds_userid = ##GDS_USERID##
gds_apikey = ##GDS_APIKEY##
gds_endpoint = https://api.sjva.me/v1/gds_auth
__EOF_END__
__EOF_START__ /docker/rclone/filter.txt
- Featurettes/**
__EOF_END__
__EOF_START__ /docker/rclone-after-service.sh
#!/bin/bash

# ff_plex는 항상 중지 및 기동
docker stop ff 2>/dev/null &
docker stop plex 2>/dev/null &
wait
echo "[정보] ff_plex 서비스가 중지되었습니다."

# kavita, jellyfin는 존재할 경우만 중지
for service in kavita jellyfin; do
  dir="/docker/$service"
  # 폴더 없으면 서비스 없음 처리
  if [ ! -d "$dir" ]; then
    continue
  fi
  # 폴더 있음 → 서비스 실행 여부 확인
  if docker ps --filter "name=$service" --format '{{.Names}}' | grep -qw "$service"; then
    if docker stop "$service" 2>/dev/null; then
      echo "[정보] $service 서비스가 정상적으로 중지되었습니다."
    else
      echo "[경고] $service 서비스 중지에 실패했습니다."
    fi
  else
    echo "[정보] $service 서비스가 실행 중이지 않습니다."
  fi
done

# 모든 서비스가 종료될때까지 대기
echo "[정보] 서비스가 완전히 중지될 때까지 3초간 대기합니다..."
sleep 3

# /mnt/rclone/DATA/GDRIVE가 마운트될 때까지 1초 간격 대기
echo "[정보] /mnt/rclone/Data/GDRIVE 마운트 상태를 확인 중입니다..."
while [ ! -d /mnt/rclone/Data/GDRIVE ]; do
  sleep 1
done
echo "[정보] /mnt/rclone/Data/GDRIVE가 마운트되었습니다."

# I/O 안정화 대기
echo "[정보] I/O 안정화를 위해 5초간 대기합니다..."
sleep 5

# ff_plex는 무조건 기동
cd /docker/ff_plex && docker compose up -d
echo "[정보] ff_plex 서비스가 시작되었습니다."

# kavita, jellyfin은 폴더 및 docker-compose.yml 확인 후 기동
for service in kavita jellyfin; do
  dir="/docker/$service"
  compose_file="$dir/docker-compose.yml"
  if [ -d "$dir" ] && [ -f "$compose_file" ]; then
    cd "$dir" && docker compose up -d
    echo "[정보] $service 서비스가 시작되었습니다."
  fi
done

exit 0
__EOF_END__
__EOF_START__ /etc/systemd/system/rclone-after-service.service
[Unit]
Description=Delayed Docker Compose Start After Rclone Mount
After=network-online.target

[Service]
Type=simple
ExecStart=/docker/rclone-after-service.sh
Restart=on-failure

[Install]
WantedBy=multi-user.target
__EOF_END__
__EOFS_END__
__DOCKER_END__

__DOCKER_START__ name=ff_plex req=true
__CMD_START__
mkdir -p /docker/ff_plex/ff && mkdir -p /docker/ff_plex/plex/{config,transcode}
__CMD_END__
__EOFS_START__
__EOF_START__ /docker/ff_plex/docker-compose.yml
services: 
  ff:
    container_name: ff
    image: flaskfarm/flaskfarm:4.0
    ports:
      - "9999:9999" # service port
      - "9998:9998" # webhook port (plex)
      - "9997:7575" # webhook port (jellyfin)
    volumes:
      - /docker/ff_plex/ff:/data
      - /:/host         # 내부 우분투까지 접근. 로그삭제같은 특수기능떄문에 허용
      - /mnt/rclone/Data:/share/gds:rshared
      # plex mate plex-docker
      - libpms:/usr/lib/plexmediaserver
      - /docker/ff_plex/plex:/plex
    privileged: true

  plex:
    container_name: plex
    image: ghcr.io/by275/plex:lsio-1.42.1.10060-4e8b05daf
    security_opt:
      - no-new-privileges:true
    ports:
      - 32400:32400
    volumes:
      - /docker/ff_plex/plex/config:/config
      - /docker/ff_plex/plex/transcode:/transcode
      - type: bind
        source: /mnt/rclone/Data
        target: /share/gds
        bind:
          propagation: rslave
      - libpms:/libpms
    devices:
      - "/dev/dri:/dev/dri"
    environment:
      - PUID=0
      - PGID=0
      - TZ=${TZ:-Asia/Seoul}
      - PLEX_CLAIM=claim-dxqdEtTdsP_88m1ZBXE1
      - VERSION=docker
      - WAIT_ANCHOR_DIRS=/share/gds/GDRIVE/VIDEO/방송중
      - WATCHER_DIRS=/share/gds/GDRIVE/VIDEO/방송중
      - WATCHER_INTERVAL=3600s
      - CLEANUP_PTC_CRON=44 44 */4 * * *
      - CLEANUP_PTC_EXCEED_GB=30
      - CLEANUP_PTC_FREEUP_GB=10
    logging:
      driver: json-file
      options:
        max-size: "1024k"
        max-file: "5"
volumes:
  libpms:

networks:
  default:
    external: true
    name: ##DOCKER_BRIDGE_NM##
__EOF_END__
__EOFS_END__
__CADDYS_START__
__CADDY_START__
    # Plex Media Server + Hook
    @plex host plex.##DOMAIN##
    handle @plex {
        reverse_proxy plex:32400 {
            header_up X-Forwarded-For {remote_host}
            header_up X-Real-IP {remote_host}
        }
    }
    @plexhook host plexhook.##DOMAIN##
    handle @plexhook {
        reverse_proxy ff:9998 {
            header_up X-Forwarded-For {remote_host}
            header_up X-Real-IP {remote_host}
        }
    }
__CADDY_END__
__CADDY_START__
    # FF
    @ff host ff.##DOMAIN##
    handle @ff {
        reverse_proxy ff:9999 {
            header_up X-Forwarded-For {remote_host}
            header_up X-Real-IP {remote_host}
        }
    }
__CADDY_END__
__CADDYS_END__
__DOCKER_END__

__DOCKER_START__ name=jellyfin req=false
__CMD_START__
mkdir -p /docker/jellyfin/{cache,config}
__CMD_END__
__EOFS_START__
__EOF_START__ /docker/jellyfin/docker-compose.yml
services:
  jellyfin:
    image: jellyfin/jellyfin:latest
    container_name: jellyfin
    devices:
      - /dev/dri:/dev/dri         # Intel/NVIDIA GPU용 초기 예시
    environment:
      - PUID=0
      - PGID=0
      - TZ=Asia/Seoul             # 시간대
    ports:
      - 8096:8096                 # Jellyfin 기본 포트
    volumes:
      - ./config:/config
      - ./cache:/cache
      - /mnt/rclone/Data/GDRIVE/VIDEO/AV:/media      # 본인의 미디어 경로로 수정
networks:
  default:
    external: true
    name: ##DOCKER_BRIDGE_NM##
__EOF_END__
__EOFS_END__
__CADDYS_START__
__CADDY_START__
    # Jellyfin
    @jellyfin host jellyfin.##DOMAIN##
    handle @jellyfin {
        reverse_proxy jellyfin:8096 {
            header_up X-Forwarded-For {remote_host}
            header_up X-Real-IP {remote_host}
        }
    }
__CADDY_END__
__CADDYS_END__
__DOCKER_END__

__DOCKER_START__ name=kavita req=false
__CMD_START__
mkdir -p /docker/kavita
__CMD_END__
__EOFS_START__
__EOF_START__ /docker/kavita/docker-compose.yml
services:
  kavita:
    container_name: kavita
    image: ghcr.io/by275/kavita:v0.8.3.2-0.4.2
    security_opt:
      - no-new-privileges:true
    logging:
      driver: json-file
      options:
        max-size: "1024k"
        max-file: "5"
    volumes:
      - ./:/kavita/config
      - /mnt/rclone/Data:/mnt/gds2:rshared
    ports:
      - "5000:5000"
    environment:
      - PUID=0
      - PGID=0
      - TZ=Asia/Seoul
      - WAIT_ANCHOR_DIRS=/mnt/gds2/GDRIVE/READING
networks:
  default:
    external: true
    name: ##DOCKER_BRIDGE_NM##
__EOF_END__
__EOFS_END__
__CADDYS_START__
__CADDY_START__
    # Kavita
    @kavita host kavita.##DOMAIN##
    handle @kavita {
        reverse_proxy kavita:5000 {
            header_up X-Forwarded-For {remote_host}
            header_up X-Real-IP {remote_host}
        }
    }
__CADDY_END__
__CADDYS_END__
__DOCKER_END__

__DOCKER_START__ name=beszel req=false
__CMD_START__
mkdir -p /docker/beszel
__CMD_END__
__EOFS_START__
__EOF_START__ /docker/beszel/docker-compose.yml
services:
  beszel:
    image: henrygd/beszel:latest
    container_name: beszel
    restart: unless-stopped
    ports:
      - "8090:8090"
    volumes:
      - ./:/beszel_data
    environment:
      - TZ=Asia/Seoul
    deploy:
      resources:
        limits:
          memory: 64M
volumes:
  beszel_data:
networks:
  default:
    external: true
    name: ##DOCKER_BRIDGE_NM##
__EOF_END__
__EOFS_END__
__CADDYS_START__
__CADDY_START__
    # Beszel
    @beszel host beszel.##DOMAIN##
    handle @beszel {
        reverse_proxy beszel:8090 {
            header_up X-Forwarded-For {remote_host}
            header_up X-Real-IP {remote_host}
        }
    }
__CADDY_END__
__CADDYS_END__
__DOCKER_END__

__DOCKER_START__ name=uptime-kuma req=false
__CMD_START__
mkdir -p /docker/uptime-kuma
__CMD_END__
__EOFS_START__
__EOF_START__ /docker/uptime-kuma/docker-compose.yml
services:
  uptime-kuma:
    container_name: uptime-kuma
    image: 'louislam/uptime-kuma:latest'
    restart: unless-stopped
    ports:
        - '3001:3001'
    volumes:
        - './:/app/data'
volumes:
  data:
    driver: local
networks:
  default:
    external: true
    name: ##DOCKER_BRIDGE_NM##
__EOF_END__
__EOFS_END__
__CADDYS_START__
__CADDY_START__
    # Uptime Kuma
    @uptime host uptime.##DOMAIN##
    handle @uptime {
        reverse_proxy uptime-kuma:3001 {
            header_up X-Forwarded-For {remote_host}
            header_up X-Real-IP {remote_host}
        }
    }
__CADDY_END__
__CADDYS_END__
__DOCKER_END__

__DOCKER_START__ name=vaultwarden req=false
__CMD_START__
mkdir -p /docker/vaultwarden
__CMD_END__
__EOFS_START__
__EOF_START__ /docker/vaultwarden/docker-compose.yml
services:
  vaultwarden:
    container_name: vaultwarden
    image: vaultwarden/server
    restart: unless-stopped
    ports:
      - 8000:80
    volumes:
      - ./:/data
    environment:
      - TZ=Asia/Seoul
networks:
  default:
    external: true
    name: ##DOCKER_BRIDGE_NM##
__EOF_END__
__EOFS_END__
__DOCKER_END__
__CADDYS_START__
__CADDY_START__
    # Vaultwarden
    @vaultwarden host pw.##DOMAIN##
    handle @vaultwarden {
        reverse_proxy vaultwarden:80 {
            header_up X-Forwarded-For {remote_host}
            header_up X-Real-IP {remote_host}
        }
    }
__CADDY_END__
__CADDYS_END__
__DOCKER_LIST_END__

__CADDYFILE_START__ /docker/caddy/conf/Caddyfile
{
    email ##email##
}

# 와일드카드 인증서로 모든 서브도메인 처리
*.##DOMAIN## {
    tls {
        dns cloudflare {env.CLOUDFLARE_API_TOKEN}
    }

    # Proxmox
    @proxmox host pve.##DOMAIN##
    handle @proxmox {
        reverse_proxy https://##PROXMOX_IP##:8006 {
            transport http {
                tls_insecure_skip_verify
            }
        }
    }

_CADDYS_

    # 기본 응답 (매칭되지 않는 서브도메인)
    handle {
        respond "🏠  Homelab Server - Service not found" 404
    }

    # 로그 설정
    log {
        output file /var/log/access.log {
            roll_size 50mb            # 로그 파일 최대 크기 (선택 사항)
            roll_keep 7               # 보관할 로그 파일 개수
            roll_keep_for 720h        # 보관 기간 (예: 720시간 = 30일)
        }
        format json       # 또는 format console
        level INFO
    }
}

# 메인 도메인 (와일드카드에 포함되지 않음)
##DOMAIN## {
    tls {
        dns cloudflare {env.CLOUDFLARE_API_TOKEN}
    }
    respond "🏠  Homelab Main Page - All services running!"
}
__CADDYFILE_END__
